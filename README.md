# transformers_pytorch
Pytorch Transformers from Scratch (Attention is all you need).  read the original transformer paper "Attention is all you need" and implement it from scratch! 
